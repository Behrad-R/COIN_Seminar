{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10526768,"sourceType":"datasetVersion","datasetId":6514968}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Coin Seminar Plant Sleep Quality Regression","metadata":{"id":"CgBUhTu9Rk7r"}},{"cell_type":"markdown","source":"## Preparation","metadata":{"id":"J8EirJsuSO2A"}},{"cell_type":"markdown","source":"First of all the required packages need to be installed.","metadata":{"id":"3MCNg3qzR1cd"}},{"cell_type":"code","source":"!pip install timm librosa torch torchvision tqdm torcheval cjm_pytorch_utils","metadata":{"id":"wJF-_qGIctW6","outputId":"09caeb15-0a38-4920-e5bf-3a3503af7b0a","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:28:52.135250Z","iopub.execute_input":"2025-02-12T09:28:52.135563Z","iopub.status.idle":"2025-02-12T09:28:55.758579Z","shell.execute_reply.started":"2025-02-12T09:28:52.135525Z","shell.execute_reply":"2025-02-12T09:28:55.757399Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Afterwards we will import all the required packages.","metadata":{"id":"EQjFJkD0lJhS"}},{"cell_type":"code","source":"import random\nimport math\nimport multiprocessing\nfrom pathlib import Path\nimport json\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport librosa, librosa.display\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom datetime import datetime\n\nfrom PIL import Image\nimport torchaudio\nfrom transformers import ASTFeatureExtractor\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport timm\nimport torch.nn as nn\nfrom torch.optim.lr_scheduler import StepLR, LambdaLR\nimport torch.optim as optim\n\nfrom torch.amp import autocast\nfrom torch.cuda.amp import GradScaler\nfrom torcheval.metrics import R2Score\nfrom cjm_pytorch_utils.core import  get_torch_device\nfrom tqdm.notebook import tqdm\nfrom google.colab import drive","metadata":{"id":"b9pMCu-hR7Jr","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:28:55.759722Z","iopub.execute_input":"2025-02-12T09:28:55.760088Z","iopub.status.idle":"2025-02-12T09:29:00.256021Z","shell.execute_reply.started":"2025-02-12T09:28:55.760052Z","shell.execute_reply":"2025-02-12T09:29:00.255161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seed = 42\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = True","metadata":{"id":"Lys6BG5m_p5b","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:00.256715Z","iopub.execute_input":"2025-02-12T09:29:00.256856Z","iopub.status.idle":"2025-02-12T09:29:00.263914Z","shell.execute_reply.started":"2025-02-12T09:29:00.256837Z","shell.execute_reply":"2025-02-12T09:29:00.263321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Move model to GPU if available\ndevice = get_torch_device()","metadata":{"id":"9I94erFCN-t3","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:00.264736Z","iopub.execute_input":"2025-02-12T09:29:00.264949Z","iopub.status.idle":"2025-02-12T09:29:00.320731Z","shell.execute_reply.started":"2025-02-12T09:29:00.264919Z","shell.execute_reply":"2025-02-12T09:29:00.320027Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The notebook will be mounted to google drive to ensure persistent files for all sessions.","metadata":{"id":"7toOvJR7Rq2A"}},{"cell_type":"markdown","source":"We will then select the directory, where all plant recordings and labels are saved.","metadata":{"id":"zJEEoPhZlX3F"}},{"cell_type":"code","source":"%cd /kaggle/input/coin-data/COIN Projekt","metadata":{"id":"NRdHI2jBMpwj","outputId":"0b1dc5eb-0b30-4fcf-ea30-6a1dec4c8822","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:00.323214Z","iopub.execute_input":"2025-02-12T09:29:00.323437Z","iopub.status.idle":"2025-02-12T09:29:00.334413Z","shell.execute_reply.started":"2025-02-12T09:29:00.323415Z","shell.execute_reply":"2025-02-12T09:29:00.333467Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Helper functions","metadata":{"id":"mdf2CXhbPEtH"}},{"cell_type":"markdown","source":"We will use the following helper function to load and preprocess the audio data. The function will create a tuple of arrays containing the Mel Frequency Cepstral Coefficients, the values for the MEL Spectrograms, the filenames, and the associated subset.","metadata":{"id":"4B4XSTTIoB0A"}},{"cell_type":"code","source":"# Load and preprocess audio data\ndef load_and_preprocess_data(data_dir, subsets, hop_length=512, n_mels=128, n_mfcc=20, fmax = 20, n_fft=2048):\n    \"\"\"Loads and preprocesses audio data from specified directories.\n\n    Args:\n      data_dir: The directory containing the audio data.\n      subsets: A list of subdirectories within `data_dir` to load data from.\n      hop_length: The hop length to use when computing the Mel spectrogram.\n      n_mels: The number of Mel frequency bins to use.\n\n    Returns:\n      A tuple containing:\n        - A list of Mel spectrograms, one for each audio file.\n        - A NumPy array of filenames corresponding to the Mel spectrograms.\n        - A list of MFCCs, one for each audio file.\n        - A list of subset names corresponding to the Mel spectrograms.\n    \"\"\"\n    data = []\n    filenames = []\n    signals = []\n    subset_names = []\n    audio_dir = data_dir\n    # We iterate through each subset\n    for i, subset in enumerate(subsets):\n      subset_dir = os.path.join(audio_dir, subset)\n      for filename in os.listdir(subset_dir):\n        try:\n          if filename.endswith('.wav'):\n              file_path = os.path.join(subset_dir, filename) # joining the path to the subset and the filename to get the full path\n              print(file_path)\n              audio_data, sample_rate = librosa.load(file_path, sr=None) # We load the audio data with librosa\n              # Perform preprocessing (e.g., convert to Mel spectrogram)\n              audio_signal = librosa.feature.mfcc(y=audio_data, sr=sample_rate, hop_length=hop_length, n_mfcc=n_mfcc, fmax=fmax, n_fft=n_fft) # Extracting Mel Frequency Cepstral Coefficients\n              mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate, n_mels=n_mels, hop_length=hop_length, fmax=fmax, n_fft=n_fft) # Extracting  Mel spectrogram\n              mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max) # We convert the amplitudes to decibel scale\n              filenames.append(filename) # Saving the filenames in case we need it later\n              subset_names.append(subset)\n              signals.append(audio_signal)\n              data.append(mel_spectrogram)\n        except:\n          pass\n    return data, np.array(filenames), signals, subset_names","metadata":{"id":"fWEX37ptr1ME","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:00.335911Z","iopub.execute_input":"2025-02-12T09:29:00.336053Z","iopub.status.idle":"2025-02-12T09:29:00.344973Z","shell.execute_reply.started":"2025-02-12T09:29:00.336036Z","shell.execute_reply":"2025-02-12T09:29:00.344230Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading the data","metadata":{"id":"SDUHzEOhpzoG"}},{"cell_type":"markdown","source":"We will load the labels separately as a Dataframe from the sleep circle data export. It is important to note that the datetime columns \"Went to bed\" and \"Woke up\" need to be converted to the datetime with the '%Y-%m-%d %H' format.","metadata":{"id":"uelD8TLApO3K"}},{"cell_type":"code","source":"sleep_circle_dir = \"./data/Labels/\"\nsleep_circle_dir","metadata":{"id":"e7NLkX2GqsDP","outputId":"17a2945a-72cb-41f1-a8ac-9db41ce65fc7","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:00.345700Z","iopub.execute_input":"2025-02-12T09:29:00.345936Z","iopub.status.idle":"2025-02-12T09:29:00.360780Z","shell.execute_reply.started":"2025-02-12T09:29:00.345892Z","shell.execute_reply":"2025-02-12T09:29:00.359957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sleep_circle_data_list = []\nfor filename in os.listdir(\"./data/Labels/\"):\n  sleep__circle_data = pd.read_csv(os.path.join(sleep_circle_dir, filename), delimiter= \";\")\n  sleep__circle_data.rename(columns={\"Start\": \"Went to bed\", \"End\": \"Woke up\"}, inplace = True)\n  sleep__circle_data[\"Went to bed\"] = pd.to_datetime(pd.to_datetime(sleep__circle_data[\"Went to bed\"]).dt.strftime('%Y-%m-%d %H'))\n  sleep__circle_data[\"Woke up\"] =  pd.to_datetime(pd.to_datetime(sleep__circle_data[\"Woke up\"]).dt.strftime('%Y-%m-%d %H'))\n  sleep__circle_data[\"subset_name\"] = filename.split(\".csv\")[0]\n  sleep_circle_data_list.append(sleep__circle_data)\nsleep_circle_df = pd.concat(sleep_circle_data_list)\nsleep_circle_df","metadata":{"id":"VkH9b-oirCVF","outputId":"e356f036-c4fb-4233-833c-c8c8d1652c21","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:00.361756Z","iopub.execute_input":"2025-02-12T09:29:00.361969Z","iopub.status.idle":"2025-02-12T09:29:00.438263Z","shell.execute_reply.started":"2025-02-12T09:29:00.361940Z","shell.execute_reply":"2025-02-12T09:29:00.437446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sleep_circle_df[\"subset_name\"].unique()","metadata":{"id":"_xN5C5fBmWmG","outputId":"4d63b309-2054-4576-da9f-59011c604f2e","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:00.439243Z","iopub.execute_input":"2025-02-12T09:29:00.439457Z","iopub.status.idle":"2025-02-12T09:29:00.444485Z","shell.execute_reply.started":"2025-02-12T09:29:00.439436Z","shell.execute_reply":"2025-02-12T09:29:00.443711Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"With the helper function we will load and preprocess the plant recordings.","metadata":{"id":"R5oFRXt0uCdO"}},{"cell_type":"code","source":"hop_length=512\nn_mels=30\nn_mfcc=20*2\nsr = 144\nn_fft= 2048\nmfcc = True\nfmax = 20","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:00.445366Z","iopub.execute_input":"2025-02-12T09:29:00.445533Z","iopub.status.idle":"2025-02-12T09:29:00.458980Z","shell.execute_reply.started":"2025-02-12T09:29:00.445502Z","shell.execute_reply":"2025-02-12T09:29:00.458107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir = './data/Audio_Data'\nsubsets = ['behrad', 'linus', 'Jasper', 'Fynn']\naudio_files, filenames, signals, subset_names  = load_and_preprocess_data(data_dir = data_dir, subsets = subsets, hop_length=hop_length, n_mels=n_mels, n_mfcc=n_mfcc, fmax = fmax, n_fft = n_fft)","metadata":{"id":"NjDBjs91r2-J","outputId":"e4a9e76c-a92c-4948-f67e-f5066d2b76ba","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:00.459900Z","iopub.execute_input":"2025-02-12T09:29:00.460208Z","iopub.status.idle":"2025-02-12T09:29:50.256636Z","shell.execute_reply.started":"2025-02-12T09:29:00.460176Z","shell.execute_reply":"2025-02-12T09:29:50.255721Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"From the filenames we extract the timestamp and convert it to the same format as the \"Went to bed\" column from the sleep circle data.","metadata":{"id":"txRQoG9ZuBUc"}},{"cell_type":"code","source":"audio_timestamps = []\nfor filename in filenames:\n  timestamp = filename.split(\"_\")[-1]\n  timestamp = timestamp.split(\".\")[0]\n  timestamp = int(timestamp)\n  timestamp = datetime.utcfromtimestamp(timestamp/1000).strftime('%Y-%m-%d %H')\n  audio_timestamps.append(timestamp)","metadata":{"id":"lns7cf6E__8w","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:50.257558Z","iopub.execute_input":"2025-02-12T09:29:50.257740Z","iopub.status.idle":"2025-02-12T09:29:50.262661Z","shell.execute_reply.started":"2025-02-12T09:29:50.257718Z","shell.execute_reply":"2025-02-12T09:29:50.261691Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We join the arrays to a single dataframe for easier use.","metadata":{"id":"9lXkVdafuZVt"}},{"cell_type":"code","source":"audio_df = pd.DataFrame(data = {\"timestamp\": audio_timestamps, \"mel_spectrogram\": audio_files, \"mfcc\": signals, \"filenames\": filenames, \"subset\": subset_names})\naudio_df['timestamp'] = pd.to_datetime(audio_df['timestamp'])\naudio_df","metadata":{"id":"xXoPf2ouCPbl","outputId":"c2ea955b-e5a0-433e-af86-fd137ccb556e","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:50.263455Z","iopub.execute_input":"2025-02-12T09:29:50.263606Z","iopub.status.idle":"2025-02-12T09:29:50.771406Z","shell.execute_reply.started":"2025-02-12T09:29:50.263588Z","shell.execute_reply":"2025-02-12T09:29:50.770357Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We will sort the sleep circle data and the plant recording data to merge both dataframe with eachother.","metadata":{"id":"tJFl0utUp3zP"}},{"cell_type":"code","source":"sleep_circle_df = sleep_circle_df.sort_values(\"Went to bed\")\n\naudio_df = audio_df.sort_values('timestamp')","metadata":{"id":"dBUAuyAUsopo","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:50.772481Z","iopub.execute_input":"2025-02-12T09:29:50.772665Z","iopub.status.idle":"2025-02-12T09:29:50.778458Z","shell.execute_reply.started":"2025-02-12T09:29:50.772642Z","shell.execute_reply":"2025-02-12T09:29:50.777668Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Because the plant recording starting time and the sleep circle timestamp sometimes do not match to the exact hour, we will merge both dataframes on the \"Went to bed\" column and the \"timestamp\" column with a range of 3 hours.","metadata":{"id":"4U4RX1Xtuym5"}},{"cell_type":"code","source":"concat_arr = []\nfor subset in subsets:\n  subset_df = audio_df[audio_df[\"subset\"] == subset]\n  sleep_circle_subset_df = sleep_circle_df[sleep_circle_df[\"subset_name\"] == subset]\n  subset_merged_df = pd.merge_asof(sleep_circle_subset_df, subset_df, left_on=\"Went to bed\", right_on =\"timestamp\", direction='nearest', tolerance=pd.Timedelta('3 hour'))\n  concat_arr.append(subset_merged_df)\nmerged_df = pd.concat(concat_arr)","metadata":{"id":"t4OSj4j8HNzl","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:50.779258Z","iopub.execute_input":"2025-02-12T09:29:50.779488Z","iopub.status.idle":"2025-02-12T09:29:50.810831Z","shell.execute_reply.started":"2025-02-12T09:29:50.779459Z","shell.execute_reply":"2025-02-12T09:29:50.810016Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We drop all rows which have null values for the mel_spectrogram. Furthermore we convert the sleep quality column to the float data type ranging from 0 to 1.","metadata":{"id":"apUFY2Mxw7-3"}},{"cell_type":"code","source":"merged_df = merged_df.dropna(subset = [\"mel_spectrogram\"]).reset_index(drop=True)\nmerged_df[\"Sleep Quality\"] = merged_df[\"Sleep Quality\"].apply(lambda x: float(x.replace(\"%\", \"\"))/100)\n#merged_df[\"Sleep Quality\"] = merged_df[\"Sleep Quality\"].apply(lambda x: float(x.replace(\"%\", \"\")))\nmerged_df","metadata":{"id":"ITzoVvF2HbCq","outputId":"47e9e859-6106-465c-894b-18bb9d68eaaa","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:50.811791Z","iopub.execute_input":"2025-02-12T09:29:50.812021Z","iopub.status.idle":"2025-02-12T09:29:51.324753Z","shell.execute_reply.started":"2025-02-12T09:29:50.811989Z","shell.execute_reply":"2025-02-12T09:29:51.323919Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df[merged_df[\"subset\"]== \"behrad\"]","metadata":{"id":"-d0ccBOjxku1","outputId":"c66f0086-ebf6-4a61-be7b-011dade3e411","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:51.325718Z","iopub.execute_input":"2025-02-12T09:29:51.325897Z","iopub.status.idle":"2025-02-12T09:29:52.493902Z","shell.execute_reply.started":"2025-02-12T09:29:51.325875Z","shell.execute_reply":"2025-02-12T09:29:52.493103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df[merged_df[\"subset\"]== \"linus\"]","metadata":{"id":"Gt80OugKyajd","outputId":"932cf309-f498-4115-c75a-fd1d23eae157","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:52.494801Z","iopub.execute_input":"2025-02-12T09:29:52.495039Z","iopub.status.idle":"2025-02-12T09:29:54.360995Z","shell.execute_reply.started":"2025-02-12T09:29:52.495008Z","shell.execute_reply":"2025-02-12T09:29:54.360097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df = merged_df[merged_df[\"Went to bed\"]<= \"2024-11-22\"].reset_index(drop=True)\nmerged_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:54.364850Z","iopub.execute_input":"2025-02-12T09:29:54.365037Z","iopub.status.idle":"2025-02-12T09:29:54.849109Z","shell.execute_reply.started":"2025-02-12T09:29:54.365017Z","shell.execute_reply":"2025-02-12T09:29:54.848317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df.columns","metadata":{"id":"OnaCA_HzrZP2","outputId":"eed01fe7-b06d-4ac5-8dae-602e05ed6645","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:54.851095Z","iopub.execute_input":"2025-02-12T09:29:54.851290Z","iopub.status.idle":"2025-02-12T09:29:54.856626Z","shell.execute_reply.started":"2025-02-12T09:29:54.851252Z","shell.execute_reply":"2025-02-12T09:29:54.855792Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualizing the data","metadata":{"id":"sgBsHhw_x1UQ"}},{"cell_type":"code","source":"merged_df[\"mel_spectrogram\"].shape","metadata":{"id":"7gIh04-lIRxq","outputId":"07dfdb59-3970-4e59-80b0-13b37302e2b0","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:54.857534Z","iopub.execute_input":"2025-02-12T09:29:54.857750Z","iopub.status.idle":"2025-02-12T09:29:54.869291Z","shell.execute_reply.started":"2025-02-12T09:29:54.857721Z","shell.execute_reply":"2025-02-12T09:29:54.868597Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df[\"mel_spectrogram\"][0]","metadata":{"id":"PAIu8izbx5PV","outputId":"dad95686-a242-436b-eecc-8a7ce1ddc502","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:54.870122Z","iopub.execute_input":"2025-02-12T09:29:54.870332Z","iopub.status.idle":"2025-02-12T09:29:54.882320Z","shell.execute_reply.started":"2025-02-12T09:29:54.870305Z","shell.execute_reply":"2025-02-12T09:29:54.881685Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.abs(merged_df[\"mfcc\"][0])","metadata":{"id":"CJgimW5Nx34_","outputId":"d389fcd7-67f8-4af3-cbe7-db12d2c2a500","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:54.883028Z","iopub.execute_input":"2025-02-12T09:29:54.883200Z","iopub.status.idle":"2025-02-12T09:29:54.895825Z","shell.execute_reply.started":"2025-02-12T09:29:54.883182Z","shell.execute_reply":"2025-02-12T09:29:54.895180Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We plot the MEL-Spectrogram and the MFCC with the librosa.display.specshow function (https://librosa.org/doc/main/generated/librosa.display.specshow.html). All values are plotted in hz units but the scale differs (MEL-Spectrogram uses mel scale while MFCC uses hz).","metadata":{"id":"-Uq9flWj19xr"}},{"cell_type":"code","source":"plt.figure(figsize=(20, 5))\nlibrosa.display.specshow(merged_df[\"mel_spectrogram\"][0], x_axis='time',\n                         y_axis='mel', sr=144, cmap= \"magma\", hop_length=512)\nplt.colorbar(label=\"hz\")\nplt.title('Mel-Spectrogram on dB Scale', fontdict=dict(size=18))\nplt.show()","metadata":{"id":"X-X0pj022Sdm","outputId":"3e9c5e36-bbaa-488b-879f-d7184fdbb79e","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:54.896647Z","iopub.execute_input":"2025-02-12T09:29:54.896893Z","iopub.status.idle":"2025-02-12T09:29:55.411843Z","shell.execute_reply.started":"2025-02-12T09:29:54.896864Z","shell.execute_reply":"2025-02-12T09:29:55.410772Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(20, 5))\nlibrosa.display.specshow(np.abs(merged_df[\"mfcc\"][0]), x_axis='time',\n                         y_axis = \"hz\", sr=144, cmap= \"magma\")\nplt.colorbar(label = \"hz\")\nplt.title(\"MFCC\", fontdict=dict(size=18))\nplt.show()","metadata":{"id":"7jy-HDRazS1w","outputId":"e83480ef-6e9a-4f0b-947f-cf0c991d7bef","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:55.412808Z","iopub.execute_input":"2025-02-12T09:29:55.412995Z","iopub.status.idle":"2025-02-12T09:29:55.972022Z","shell.execute_reply.started":"2025-02-12T09:29:55.412971Z","shell.execute_reply":"2025-02-12T09:29:55.971146Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We will also visualize the waveform to look at the peaks of amiplitudes (https://librosa.org/doc/main/generated/librosa.display.waveshow.html).","metadata":{"id":"Msj4frOh38Rn"}},{"cell_type":"code","source":"plt.figure(figsize=(20, 5))\nlibrosa.display.waveshow(merged_df[\"mfcc\"][0], sr = 144)\nplt.title(\"Waveplot\", fontdict=dict(size=18))\nplt.xlabel(\"Time\", fontdict=dict(size=15))\nplt.ylabel(\"Amplitude\", fontdict=dict(size=15))\nplt.show()","metadata":{"id":"AuOXuIjuvO2M","outputId":"0eb3ca55-56bf-48a1-d45d-960165003149","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:55.972803Z","iopub.execute_input":"2025-02-12T09:29:55.972986Z","iopub.status.idle":"2025-02-12T09:29:56.237304Z","shell.execute_reply.started":"2025-02-12T09:29:55.972964Z","shell.execute_reply":"2025-02-12T09:29:56.236527Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Image Classification Neural Networks","metadata":{"id":"q_to-85N4T6I"}},{"cell_type":"markdown","source":"## Model loading","metadata":{"id":"jGnvzKi7GJOj"}},{"cell_type":"code","source":"# Load a pretrained model from timm\n\n#model = timm.create_model('resnet18', pretrained=True)\nmodel = timm.create_model('eva02_base_patch14_448.mim_in22k_ft_in22k_in1k', pretrained=True, num_classes=1)\nmodel","metadata":{"id":"tjY-8kMWGLRR","outputId":"c5d4fa2c-8151-4922-8e0f-9dc54fda2be3","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:56.238264Z","iopub.execute_input":"2025-02-12T09:29:56.238503Z","iopub.status.idle":"2025-02-12T09:29:57.737088Z","shell.execute_reply.started":"2025-02-12T09:29:56.238470Z","shell.execute_reply":"2025-02-12T09:29:57.736446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.pretrained_cfg","metadata":{"id":"wMgURCExJHVg","outputId":"68cd4b41-3486-4bf5-aebe-101ed6614069","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:57.737796Z","iopub.execute_input":"2025-02-12T09:29:57.737940Z","iopub.status.idle":"2025-02-12T09:29:57.742991Z","shell.execute_reply.started":"2025-02-12T09:29:57.737923Z","shell.execute_reply":"2025-02-12T09:29:57.742371Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Dataset","metadata":{"id":"M1DGX6zQ50Ix"}},{"cell_type":"markdown","source":"We create a custom dataframe object for the mfcc or the melspectrogram.","metadata":{"id":"B06Ug9sm55DE"}},{"cell_type":"code","source":"class AudioDataset(Dataset):\n    def __init__(self, audio_data, labels, transform=None):\n        self.audio_data = audio_data\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.audio_data)\n\n    def __getitem__(self, idx):\n        # Load mel spectrogram\n        mel_spectrogram = np.dstack([self.audio_data[idx], self.audio_data[idx], self.audio_data[idx]])\n\n        # Apply transforms if specified\n        if self.transform:\n            mel_spectrogram = self.transform(mel_spectrogram)\n\n        label = self.labels[idx]\n\n        return mel_spectrogram, label\n\n# Define transform to convert numpy arrays to torch tensors and normalize\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize(model.pretrained_cfg[\"input_size\"][1:]),  # Match input size expected by the model\n    transforms.Normalize(mean=model.pretrained_cfg[\"mean\"], std=model.pretrained_cfg[\"std\"])\n])","metadata":{"id":"3SCIRIFP54kV","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:57.743897Z","iopub.execute_input":"2025-02-12T09:29:57.744106Z","iopub.status.idle":"2025-02-12T09:29:57.756605Z","shell.execute_reply.started":"2025-02-12T09:29:57.744076Z","shell.execute_reply":"2025-02-12T09:29:57.755903Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"First we split the dataframe into train and validation set.","metadata":{"id":"Z-d3qcMy5lw7"}},{"cell_type":"code","source":"merged_df\n\n#merged_df[\"Sleep Quality\"] = (merged_df[\"Sleep Quality\"]- merged_df[\"Sleep Quality\"].abs().min())/ (merged_df[\"Sleep Quality\"].abs().max() - merged_df[\"Sleep Quality\"].abs().min())\n\ntrain_df = merged_df.sample(frac=0.8, random_state=42)\nval_df = merged_df.drop(train_df.index).reset_index(drop=True)\ntrain_df = train_df.reset_index(drop=True)\ntrain_df","metadata":{"id":"7X4_q0W95k8s","outputId":"08b359c1-cfc3-48be-bc48-517b11447aa7","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:29:57.757476Z","iopub.execute_input":"2025-02-12T09:29:57.757680Z","iopub.status.idle":"2025-02-12T09:30:00.403960Z","shell.execute_reply.started":"2025-02-12T09:29:57.757651Z","shell.execute_reply":"2025-02-12T09:30:00.403189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_df","metadata":{"id":"Sio2f7lD2Omh","outputId":"383d7ffb-c147-4753-85f1-6aab3c842b50","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:30:00.404872Z","iopub.execute_input":"2025-02-12T09:30:00.405070Z","iopub.status.idle":"2025-02-12T09:30:01.098965Z","shell.execute_reply.started":"2025-02-12T09:30:00.405049Z","shell.execute_reply":"2025-02-12T09:30:01.098189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.merge(val_df, on=[\"filenames\", \"Sleep Quality\"], how = \"inner\")","metadata":{"id":"SQnCo1W42Ewp","outputId":"e3096c6d-a719-4a16-d681-ed94ea30d57f","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:30:01.099796Z","iopub.execute_input":"2025-02-12T09:30:01.099963Z","iopub.status.idle":"2025-02-12T09:30:01.113817Z","shell.execute_reply.started":"2025-02-12T09:30:01.099931Z","shell.execute_reply":"2025-02-12T09:30:01.113161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set the number of worker processes for loading data. This should be the number of CPUs available.\nnum_workers = multiprocessing.cpu_count()#//2\nbatch_size = 4\n# Define parameters for DataLoader\ndata_loader_params = {\n    'batch_size': batch_size,  # Batch size for data loading\n    'num_workers': num_workers,  # Number of subprocesses to use for data loading\n    'persistent_workers': True,  # If True, the data loader will not shutdown the worker processes after a dataset has been consumed once. This allows to maintain the worker dataset instances alive.\n    'pin_memory': 'cuda' in device,  # If True, the data loader will copy Tensors into CUDA pinned memory before returning them. Useful when using GPU.\n    'pin_memory_device': device if 'cuda' in device else '',  # Specifies the device where the data should be loaded. Commonly set to use the GPU.\n}","metadata":{"id":"mxEXOyT4N2pf","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:30:01.114680Z","iopub.execute_input":"2025-02-12T09:30:01.114824Z","iopub.status.idle":"2025-02-12T09:30:01.127964Z","shell.execute_reply.started":"2025-02-12T09:30:01.114807Z","shell.execute_reply":"2025-02-12T09:30:01.127345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Instantiate the dataset\ndataset_train = AudioDataset(audio_data=train_df[\"mfcc\"], labels=train_df[\"Sleep Quality\"], transform=transform)\ndataset_val = AudioDataset(audio_data=val_df[\"mfcc\"], labels=val_df[\"Sleep Quality\"], transform=transform)\n\n# Create a DataLoader\ndata_loader = DataLoader(dataset_train, **data_loader_params, shuffle=True)\ndata_loader_val = DataLoader(dataset_val, **data_loader_params, shuffle=False)","metadata":{"id":"P8qCc4qT6CbA","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:30:01.128853Z","iopub.execute_input":"2025-02-12T09:30:01.129072Z","iopub.status.idle":"2025-02-12T09:30:01.143505Z","shell.execute_reply.started":"2025-02-12T09:30:01.129044Z","shell.execute_reply":"2025-02-12T09:30:01.142857Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"It is important to note that we are doing a regression task, therefore we need to change the last layer to have only one output feature.","metadata":{"id":"k180h7d--yi9"}},{"cell_type":"markdown","source":"### Model training","metadata":{"id":"L7K6slrmAy-W"}},{"cell_type":"code","source":"model = model.to(device)","metadata":{"id":"B2FtrIRc4hPE","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:30:01.144289Z","iopub.execute_input":"2025-02-12T09:30:01.144524Z","iopub.status.idle":"2025-02-12T09:30:01.384358Z","shell.execute_reply.started":"2025-02-12T09:30:01.144495Z","shell.execute_reply":"2025-02-12T09:30:01.383688Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_warmup_scheduler(optimizer, num_warmup_steps, total_steps):\n    \"\"\"\n    Returns a scheduler with a linear warmup phase.\n\n    :param optimizer: Optimizer to adjust the learning rate for.\n    :param num_warmup_steps: Number of steps for the warmup phase.\n    :param total_steps: Total number of training steps.\n    \"\"\"\n    def lr_lambda(current_step):\n        if current_step < num_warmup_steps:\n            return float(current_step) / float(max(1, num_warmup_steps))\n        return max(0.0, float(total_steps - current_step) / float(max(1, total_steps - num_warmup_steps)))\n\n    return LambdaLR(optimizer, lr_lambda)","metadata":{"id":"zMsk5Bt1E1NT","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:30:01.385160Z","iopub.execute_input":"2025-02-12T09:30:01.385346Z","iopub.status.idle":"2025-02-12T09:30:01.389701Z","shell.execute_reply.started":"2025-02-12T09:30:01.385316Z","shell.execute_reply":"2025-02-12T09:30:01.388930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class WarmupDecayScheduler(optim.lr_scheduler._LRScheduler):\n    def __init__(self, optimizer, warmup_steps, total_steps, min_lr=0, last_epoch=-1):\n        self.warmup_steps = warmup_steps\n        self.total_steps = total_steps\n        self.min_lr = min_lr\n        super(WarmupDecayScheduler, self).__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        current_step = self.last_epoch + 1\n        if current_step < self.warmup_steps:\n            # Warmup phase: Linear increase\n            scale = current_step / self.warmup_steps\n        else:\n            # Decay phase: Cosine decay\n            decay_steps = self.total_steps - self.warmup_steps\n            scale = max(\n                0,\n                0.5 * (1 + math.cos(math.pi * (current_step - self.warmup_steps) / decay_steps))\n            )\n        return [\n            self.min_lr + (base_lr - self.min_lr) * scale\n            for base_lr in self.base_lrs\n        ]","metadata":{"id":"h6LssHQXbWmz","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:30:01.390416Z","iopub.execute_input":"2025-02-12T09:30:01.390606Z","iopub.status.idle":"2025-02-12T09:30:01.402919Z","shell.execute_reply.started":"2025-02-12T09:30:01.390586Z","shell.execute_reply":"2025-02-12T09:30:01.402304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lr = 1e-4\nepochs = 5*3\n# Define loss and optimizer\ncriterion = nn.HuberLoss(reduction='mean', delta=0.20)\noptimizer = torch.optim.AdamW(model.parameters(), lr=lr, eps=1e-8)\nmetric = R2Score()\n# Define warmup and total steps\ntotal_steps = len(data_loader) * epochs\nwarmup_ratio = 0.1\nnum_warmup_steps = int(warmup_ratio * total_steps)\n\n# Create scheduler\n#lr_scheduler = get_warmup_scheduler(optimizer, num_warmup_steps, total_steps)\nlr_scheduler = WarmupDecayScheduler(optimizer, num_warmup_steps, total_steps, min_lr=1e-6)","metadata":{"id":"ftLJs29ZE5Pa","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:30:01.403631Z","iopub.execute_input":"2025-02-12T09:30:01.403763Z","iopub.status.idle":"2025-02-12T09:30:01.421853Z","shell.execute_reply.started":"2025-02-12T09:30:01.403747Z","shell.execute_reply":"2025-02-12T09:30:01.421076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"step_size = 3\ngamma = 0.5\n\n# Scheduler\n#scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)","metadata":{"id":"DEipPwCb4mR7","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:30:01.422811Z","iopub.execute_input":"2025-02-12T09:30:01.423004Z","iopub.status.idle":"2025-02-12T09:30:01.432597Z","shell.execute_reply.started":"2025-02-12T09:30:01.422978Z","shell.execute_reply":"2025-02-12T09:30:01.431834Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The trainings loop was adapted and inspired by the tutorial from Christian Mills about [Fine-Tuning Image Classifiers with PyTorch and the timm library for Beginners](https://christianjmills.com/posts/pytorch-train-image-classifier-timm-hf-tutorial/#preparing-the-data).","metadata":{}},{"cell_type":"code","source":"# Function to run a single training/validation epoch\ndef run_epoch(model, dataloader, optimizer, metric, lr_scheduler, device, scaler, epoch_id, criterion, is_training):\n    # Set model to training mode if 'is_training' is True, else set to evaluation mode\n    model.train() if is_training else model.eval()\n\n    # Reset the performance metric\n    metric.reset()\n    # Initialize the average loss for the current epoch\n    epoch_loss = 0\n    # Initialize progress bar with total number of batches in the dataloader\n    progress_bar = tqdm(total=len(dataloader), desc=\"Train\" if is_training else \"Eval\")\n\n    # Iterate over data batches\n    for batch_id, (inputs, labels) in enumerate(dataloader):\n        # Move inputs and labels to the specified device (e.g., GPU)\n        inputs, labels = inputs.to(device), labels.to(device)\n\n\n        # Forward pass\n        outputs = model(inputs).squeeze()  # Get predictions\n        loss = criterion(outputs, labels.float())\n\n        # Update the performance metric\n        metric.update(outputs.detach().cpu().squeeze(), labels.detach().cpu())\n\n        # If in training mode\n        if is_training:\n            if scaler:\n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                old_scaler = scaler.get_scale()\n                scaler.update()\n                new_scaler = scaler.get_scale()\n                if new_scaler >= old_scaler:\n                    lr_scheduler.step()\n            else:\n                loss.backward()\n                optimizer.step()\n                lr_scheduler.step()\n            # Zero the parameter gradients\n            optimizer.zero_grad()\n\n        loss_item = loss.item()\n        epoch_loss += loss_item\n        # Update progress bar\n        progress_bar.set_postfix(R_2_Score=metric.compute().item(),\n                                 loss=loss_item,\n                                 avg_loss=epoch_loss/(batch_id+1),\n                                 lr=lr_scheduler.get_last_lr()[0] if is_training else \"\")\n        progress_bar.update()\n\n        # If loss is NaN or infinity, stop training\n        if is_training:\n            stop_training_message = f\"Loss is NaN or infinite at epoch {epoch_id}, batch {batch_id}. Stopping training.\"\n            assert not math.isnan(loss_item) and math.isfinite(loss_item), stop_training_message\n\n    progress_bar.close()\n    return epoch_loss / (batch_id + 1)\n\n\n# Main training loop\ndef train_loop(model, train_dataloader, valid_dataloader, optimizer, metric, lr_scheduler, device, epochs, criterion, use_scaler=False):\n    # Initialize a gradient scaler for mixed-precision training if the device is a CUDA GPU\n    scaler = GradScaler() if device.type == 'cuda' and use_scaler else None\n    best_loss = float('inf')\n\n    # Iterate over each epoch\n    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n        # Run training epoch and compute training loss\n        train_loss = run_epoch(model, train_dataloader, optimizer, metric, lr_scheduler, device, scaler, epoch, criterion,  is_training=True)\n        # Run validation epoch and compute validation loss\n        with torch.no_grad():\n            valid_loss = run_epoch(model, valid_dataloader, None, metric, None, device, scaler, epoch, criterion, is_training=False)\n\n        # If current validation loss is lower than the best one so far, save model and update best loss\n        if valid_loss < best_loss:\n            best_loss = valid_loss\n            metric_value = metric.compute().item()\n            #torch.save(model.state_dict(), checkpoint_path)\n\n            training_metadata = {\n                'epoch': epoch,\n                'train_loss': train_loss,\n                'valid_loss': valid_loss,\n                'metric_value': metric_value,\n                'learning_rate': lr_scheduler.get_last_lr()[0],\n            }\n\n            # Save best_loss and metric_value in a JSON file\n            #with open(Path(checkpoint_path.parent/'training_metadata.json'), 'w') as f:\n            #    json.dump(training_metadata, f)\n\n    # If the device is a GPU, empty the cache\n    if device.type != 'cpu':\n        getattr(torch, device.type).empty_cache()","metadata":{"id":"EECDQfSu4n3b","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:30:01.433325Z","iopub.execute_input":"2025-02-12T09:30:01.433537Z","iopub.status.idle":"2025-02-12T09:30:01.445877Z","shell.execute_reply.started":"2025-02-12T09:30:01.433509Z","shell.execute_reply":"2025-02-12T09:30:01.445176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"checkpoint_path = \"Nichts\"","metadata":{"id":"m4ELRk-vQQIc","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:30:01.446815Z","iopub.execute_input":"2025-02-12T09:30:01.447013Z","iopub.status.idle":"2025-02-12T09:30:01.460911Z","shell.execute_reply.started":"2025-02-12T09:30:01.446990Z","shell.execute_reply":"2025-02-12T09:30:01.460167Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loop(model=model,\n           train_dataloader=data_loader,\n           valid_dataloader=data_loader_val,\n           optimizer=optimizer,\n           metric=metric,\n           lr_scheduler=lr_scheduler,\n           device=torch.device(device),\n           epochs=epochs,\n           use_scaler = True,\n           #checkpoint_path=checkpoint_path,\n           criterion = criterion)","metadata":{"id":"phlw7hw7PnDA","outputId":"40e0d296-2905-4d36-dad7-1fdf690c1d52","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:30:01.461845Z","iopub.execute_input":"2025-02-12T09:30:01.462053Z","iopub.status.idle":"2025-02-12T09:34:16.611398Z","shell.execute_reply.started":"2025-02-12T09:30:01.462024Z","shell.execute_reply":"2025-02-12T09:34:16.610562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure the model is in evaluation mode\nmodel.eval()\n\n# Perform inference\npredictions = []\nwith torch.no_grad():  # Disable gradient computation for inference\n    for inputs, labels in data_loader_val:\n        # Move data to device\n        mel_spectrogram = inputs.to(device)\n\n        # Forward pass\n        output = model(mel_spectrogram)\n\n        # Iterate through each element in the output and label tensors and append them to the predictions list\n        for out, lab in zip(output.squeeze(), labels):\n            predictions.append((out.item(), lab.item()))\n\n# Print the predictions\nfor i, pred in enumerate(predictions):\n    print(f\"Prediction for audio {i}: {pred[0]}  Actual value for audio {i}: {pred[1]}\")","metadata":{"id":"dze-kkws4u-D","outputId":"96244047-3756-4595-c6ee-929df91cd477","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:34:16.612636Z","iopub.execute_input":"2025-02-12T09:34:16.612873Z","iopub.status.idle":"2025-02-12T09:34:17.871552Z","shell.execute_reply.started":"2025-02-12T09:34:16.612850Z","shell.execute_reply":"2025-02-12T09:34:17.870674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import r2_score, mean_squared_error\n\n\n# Separate the predicted and true values\npredicted, true = zip(*predictions)\n\n# Compute the R² score\nr2 = r2_score(true, predicted)\nMSE = mean_squared_error(true, predicted)\nprint(\"R² Score:\", r2)\nprint(\"MSE Loss:\", MSE)","metadata":{"id":"QzyaGsLuvLxQ","outputId":"8d0dbafc-9331-4c23-fc57-3161d16d666a","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T09:34:17.872690Z","iopub.execute_input":"2025-02-12T09:34:17.872917Z","iopub.status.idle":"2025-02-12T09:34:17.925987Z","shell.execute_reply.started":"2025-02-12T09:34:17.872885Z","shell.execute_reply":"2025-02-12T09:34:17.925425Z"}},"outputs":[],"execution_count":null}]}
